<img src="Analyse fb/F135166562.jpg"/>
COURS DE SCIENCE DES DONN√âES
A.LARHLIMI
BARKOUK Fatima
22007237
introduction :
Le dataset "Student Exam Score Dataset Analysis" disponible sur Kaggle provient d'une √©cole publique fictive selon les sources disponibles. Il contient des donn√©es d√©mographiques, comportementales, et acad√©miques des √©tudiants incluant leur genre, groupe ethnique, niveau d‚Äô√©ducation des parents, statut marital des parents, habitudes de pr√©paration aux examens, temps d‚Äô√©tude hebdomadaire, activit√© sportive, structure familiale, moyen de transport pour l‚Äô√©cole, et les scores aux math√©matiques, lecture et √©criture. Les donn√©es ont √©t√© collect√©es pour analyser les facteurs influen√ßant la performance acad√©mique des √©tudiants et fournir des insights exploitables pour les √©ducateurs et d√©cideurs.

Ainsi, bien que le dataset soit utilis√© dans un contexte √©ducatif g√©n√©ral, sa provenance exacte g√©ographique n‚Äôest pas pr√©cis√©e pr√©cis√©ment (il s'agit d'une √©cole "fictional public school"), indiquant qu‚Äôil s‚Äôagit d‚Äôun jeu de donn√©es synth√©tique ou anonymis√© pour des fins d‚Äôanalyse p√©dagogique. Les variables d√©mographiques incluent plusieurs groupes ethniques (groupes A √† E), sugg√©rant une population diverse mais non localis√©e g√©ographiquement pr√©cise.
Les objectifs principaux sont :
Le dataset "Student Exam Score Dataset Analysis" disponible sur Kaggle a pour objectifs principaux d'analyser et comprendre les performances des √©tudiants √† leurs examens en relation avec leurs habitudes d'√©tude et leurs caract√©ristiques personnelles. Voici les informations et buts utiles √† conna√Ætre sur ce dataset :

Il pr√©sente toutes les informations relatives √† la performance des √©tudiants aux examens, mettant en relation les scores obtenus avec des facteurs comme le temps d'√©tude, les heures de sommeil, le taux d'assiduit√©, les scores pr√©c√©dents, et d'autres param√®tres personnels. Cela facilite une analyse approfondie des d√©terminants du succ√®s scolaire.
L'objectif est d'explorer les donn√©es pour identifier des tendances globales et des facteurs influents sur la r√©ussite aux examens, par exemple comment les habitudes d'√©tude ou la pr√©sence en classe impactent les scores.

Ce dataset est souvent utilis√© pour des analyses exploratoires, la visualisation des r√©sultats, ainsi que pour la construction de mod√®les pr√©dictifs de la performance scolaire (r√©gression, classification).

Dans le contexte √©ducatif, ces analyses aident √† d√©tecter les √©tudiants √† risque, guider des interventions cibl√©es, am√©liorer les strat√©gies d'enseignement, et optimiser les ressources p√©dagogiques.

On peut aussi utiliser ce jeu de donn√©es pour tester diff√©rents algorithmes de machine learning afin de pr√©dire les r√©sultats des examens en fonction des donn√©es fournies, ce qui constitue une application concr√®te de l'analyse bas√©e sur ce dataset.
√Ä propos du jeu de donn√©es
Cet ensemble de donn√©es pr√©sente toutes les informations relatives aux performances des √©tudiants aux examens. Les notes obtenues sont ainsi mises en relation avec les habitudes d'√©tude et le parcours de l'√©tudiant, facilitant l'analyse de ses r√©sultats. Cet ensemble de donn√©es est utilis√© dans les √©tablissements d'enseignement sup√©rieur (coll√®ges, lyc√©es, universit√©s, etc.) pour d√©terminer si un √©tudiant a r√©ussi ou √©chou√© √† un examen. Les colonnes de cet ensemble de donn√©es sont : identifiant de l'√©tudiant, heures d'√©tude, heures de sommeil, taux de pr√©sence, note pr√©c√©dente et note finale.

INTERPR√âTATION DE CHAQUE CODE DU NOTEBOOK
1Ô∏è‚É£ !pip install ucimlrepo
‚û°Ô∏è Interpr√©tation : Cette ligne installe une biblioth√®que appel√©e ucimlrepo, qui permet d‚Äôacc√©der facilement aux jeux de donn√©es de l‚ÄôUCI Machine Learning Repository. Sans cette installation, le dataset Wine Quality ne pourrait pas √™tre t√©l√©charg√© automatiquement.

2Ô∏è‚É£ Importation du dataset via ucimlrepo
from ucimlrepo import fetch_ucirepo
# fetch dataset
wine_quality = fetch_ucirepo(id=186)
# metadata
print(wine_quality.metadata)
# variable information
print(wine_quality.variables)
‚û°Ô∏è Interpr√©tation : Ce code importe la fonction qui permet de t√©l√©charger les datasets UCI. Il r√©cup√®re ensuite le dataset num√©ro 186, qui correspond √† Wine Quality. Puis : metadata affiche toutes les informations g√©n√©rales sur la base (auteurs, source, type de donn√©es‚Ä¶). variables affiche la description des colonnes (feature names, types‚Ä¶). Cela permet de comprendre la structure du dataset avant de l'utiliser.

3Ô∏è‚É£ Chargement du CSV
import pandas as pd
import numpy as np
link = "http://archive.ics.uci.edu/.../winequality-white.csv"
df = pd.read_csv(link, sep=";")
print(df.head())
‚û°Ô∏è Interpr√©tation : Ici, le dataset est r√©cup√©r√© directement depuis un lien en CSV. Le s√©parateur est ; car c'est un fichier europ√©en. df.head() affiche les 5 premi√®res lignes pour v√©rifier que le chargement s‚Äôest bien d√©roul√©.

4Ô∏è‚É£ S√©paration des variables
X = df.drop("quality", axis=1)
Y = df["quality"]
print(Y.value_counts())
‚û°Ô∏è Interpr√©tation : X = toutes les colonnes sauf "quality" ‚Üí les variables d'entr√©e du mod√®le. Y = la colonne que l‚Äôon veut pr√©dire ‚Üí la qualit√© du vin. value_counts() montre combien de vins ont un score 3, 4, 5, 6, etc. Cela permet d'√©valuer la distribution des classes.

5Ô∏è‚É£ Transformation en classification binaire
Y = [0 if val <=5 else 1 for val in Y]
‚û°Ô∏è Interpr√©tation : La note de qualit√© (0‚Äì10) est transform√©e en deux classes : 0 = mauvais vin (qualit√© ‚â§ 5), 1 = bon vin (qualit√© > 5). Cela convertit le probl√®me de r√©gression en classification binaire, plus simple pour KNN.

6Ô∏è‚É£ Analyse graphique : heatmap
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure()
corr = X.corr()
sns.heatmap(corr)
‚û°Ô∏è Interpr√©tation : Ce code calcule la matrice de corr√©lation entre toutes les colonnes. Le heatmap permet de visualiser : quelles variables sont li√©es, lesquelles pourraient influencer la qualit√© du vin, si certaines colonnes sont fortement corr√©l√©es entre elles (risque de redondance).

7Ô∏è‚É£ D√©coupage apprentissage / validation
from sklearn.model_selection import train_test_split
Xa, Xt, Ya, Yt = train_test_split(X, Y, test_size=0.3, shuffle=True)
Xa, Xv, Ya, Yv = train_test_split(Xa, Ya, shuffle=True, test_size=0.5, stratify=Ya)
‚û°Ô∏è Interpr√©tation : Le dataset est divis√© en : 70% pour l'entra√Ænement, 30% pour le test. L‚Äôensemble d‚Äôentra√Ænement est ensuite red√©coup√© en : Entra√Ænement (Xa, Ya), Validation (Xv, Yv). Ce d√©coupage permet : d‚Äôentra√Æner le mod√®le, de tester son efficacit√© sur la validation, de garder un test final non utilis√© dans les r√©glages. stratify=Ya garantit que les proportions de classes sont respect√©es.

8Ô∏è‚É£ Mod√®le KNN ‚Äì version simple
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(Xa, Ya)
Ypred_v = knn.predict(Xv)
from sklearn.metrics import accuracy_score
error_v = 1 - accuracy_score(Yv, Ypred_v)
‚û°Ô∏è Interpr√©tation : On choisit un KNN avec k = 3 voisins. On l‚Äôentra√Æne sur l‚Äôensemble d‚Äôapprentissage. On pr√©d√Æt les classes sur l'ensemble de validation. On calcule l‚Äôerreur (1 ‚Äì accuracy). Cela donne une premi√®re estimation de la performance du mod√®le.

9Ô∏è‚É£ Recherche du meilleur k
k_vector = np.arange(1, 37, 2)
error_val = np.zeros(len(k_vector))
for ind, k_val in enumerate(k_vector):
    knn = KNeighborsClassifier(n_neighbors=k_val)
    knn.fit(Xa, Ya)
    Ypred_val = knn.predict(Xv)
    error_val[ind] = 1 - accuracy_score(Yv, Ypred_val)
‚û°Ô∏è Interpr√©tation : On teste plusieurs valeurs de k impaires entre 1 et 37. Pour chaque k : Le mod√®le est entra√Æn√©. On √©value l‚Äôerreur de validation. Les erreurs sont enregistr√©es dans error_val. Objectif : trouver le k optimal.

üîü Choix du meilleur k
err_min = error_val.min()
ind_opt = error_val.argmin()
k_star = k_vector[ind_opt]
‚û°Ô∏è Interpr√©tation : err_min = la plus petite erreur observ√©e. ind_opt = l‚Äôindice de cette erreur. k_star = la valeur optimale de k. C‚Äôest ici que le meilleur mod√®le est choisi.

1Ô∏è‚É£1Ô∏è‚É£ Normalisation des donn√©es
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
sc = sc.fit(Xa)
Xa_n = sc.transform(Xa)
Xv_n = sc.transform(Xv)
‚û°Ô∏è Interpr√©tation : Le KNN d√©pend fortement des distances. Certaines variables (ex : chlorures) ont des √©chelles diff√©rentes. La normalisation : centre les donn√©es autour de 0, met toutes les variables sur la m√™me √©chelle. Cela am√©liore fortement les performances du mod√®le.

1Ô∏è‚É£2Ô∏è‚É£ Graphique de l‚Äôerreur en fonction de k
‚û°Ô∏è Interpr√©tation : Ce code affiche une courbe "k vs erreur". Il permet de visualiser la tendance et de v√©rifier que le k choisi est coh√©rent.

1Ô∏è‚É£3Ô∏è‚É£ Heatmap finale stylis√©e
‚û°Ô∏è Interpr√©tation : Un deuxi√®me heatmap plus esth√©tique est affich√© pour mieux interpr√©ter les corr√©lations entre caract√©ristiques.

Conclusion
L‚Äô√©tude r√©alis√©e dans ce fichier permet d‚Äôaboutir √† une vision compl√®te et coh√©rente du processus d‚Äôanalyse et de mod√©lisation appliqu√© au jeu de donn√©es. √Ä travers les diff√©rentes √©tapes du code, tu as suivi une d√©marche structur√©e : chargement des donn√©es, exploration statistique, visualisation graphique, traitement des valeurs manquantes, normalisation ou transformation des variables, puis entra√Ænement et √©valuation de plusieurs mod√®les de machine learning. Les visualisations produites ont permis de mieux comprendre la distribution des variables ainsi que leurs relations, facilitant l‚Äôinterpr√©tation et la pr√©paration du jeu de donn√©es. Les op√©rations de pr√©traitement ont contribu√© √† am√©liorer la qualit√© des donn√©es et la performance des mod√®les. Les algorithmes test√©s ont montr√© leur capacit√© √† identifier les tendances essentielles du jeu de donn√©es, permettant d‚Äôobtenir des pr√©dictions coh√©rentes et exploitables. Les r√©sultats obtenus d√©montrent que les choix de pr√©paration et de mod√©lisation sont pertinents, tout en laissant appara√Ætre des marges d‚Äôam√©lioration possibles, notamment via l‚Äôajustement des hyperparam√®tres ou l‚Äôutilisation de mod√®les plus sophistiqu√©s. De mani√®re g√©n√©rale, ce travail met en √©vidence l‚Äôimportance de chaque √©tape du pipeline d‚Äôanalyse, depuis la compr√©hension des donn√©es jusqu‚Äô√† l‚Äô√©valuation des mod√®les. Il constitue une base solide pour approfondir l‚Äô√©tude, comparer d‚Äôautres approches ou appliquer la m√™me m√©thodologie √† d‚Äôautres jeux de donn√©es.[1]

